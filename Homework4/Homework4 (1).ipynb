{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbe60765",
   "metadata": {},
   "source": [
    "## 1. 加载数据\n",
    "可以看到 IMDB_Dataset 的加载结果是一个 (50000, 2) 形状的 DataFrame。一共 50000 个样本，每个样本占一行，包含两列 ———— 第 0 列为 review，第 1 列为 sentiment。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb995635",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T03:10:04.078177Z",
     "iopub.status.busy": "2025-06-27T03:10:04.077846Z",
     "iopub.status.idle": "2025-06-27T03:10:07.016437Z",
     "shell.execute_reply": "2025-06-27T03:10:07.014915Z",
     "shell.execute_reply.started": "2025-06-27T03:10:04.078134Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据前5行:\n",
      "                                              review sentiment\n",
      "0  One of the other reviewers has mentioned that ...  positive\n",
      "1  A wonderful little production. <br /><br />The...  positive\n",
      "2  I thought this was a wonderful way to spend ti...  positive\n",
      "3  Basically there's a family where a little boy ...  negative\n",
      "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
      "\n",
      "数据信息:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   review     50000 non-null  object\n",
      " 1   sentiment  50000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 781.4+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
    "\n",
    "current_working_directory = os.getcwd()\n",
    "csv_path = os.path.join(current_working_directory, 'IMDB_Dataset.csv')\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# 查看数据信息\n",
    "print(\"数据前5行:\")\n",
    "print(df.head())\n",
    "print(\"\\n数据信息:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0f9b09",
   "metadata": {},
   "source": [
    "## 2. 数据规范化\n",
    "注意到样本的 sentiment 属性为 'positive' / 'negative'，将其映射到 1 / 0 便于处理。 另外，样本的 review 属性为 HTML 格式，需要进行去除 HTML 标签，大写字母全部改为小写等操作，将文本格式统一。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afce42d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T03:10:07.017907Z",
     "iopub.status.busy": "2025-06-27T03:10:07.017691Z",
     "iopub.status.idle": "2025-06-27T03:10:10.466533Z",
     "shell.execute_reply": "2025-06-27T03:10:10.465273Z",
     "shell.execute_reply.started": "2025-06-27T03:10:07.017890Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "文本清洗效果:\n",
      "                                              review  \\\n",
      "0  One of the other reviewers has mentioned that ...   \n",
      "1  A wonderful little production. <br /><br />The...   \n",
      "2  I thought this was a wonderful way to spend ti...   \n",
      "3  Basically there's a family where a little boy ...   \n",
      "4  Petter Mattei's \"Love in the Time of Money\" is...   \n",
      "\n",
      "                                      cleaned_review  \n",
      "0  one of the other reviewers has mentioned that ...  \n",
      "1  a wonderful little production the filming tech...  \n",
      "2  i thought this was a wonderful way to spend ti...  \n",
      "3  basically theres a family where a little boy j...  \n",
      "4  petter matteis love in the time of money is a ...  \n"
     ]
    }
   ],
   "source": [
    "# 将 'positive'/'negative' 转换为 1/0\n",
    "df['sentiment'] = df['sentiment'].map({'positive': 1, 'negative': 0})\n",
    "\n",
    "def clean_text(text):\n",
    "    # 去除HTML标签\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    # 只保留字母和空格\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text, re.I|re.A)\n",
    "    # 全部转换为小写\n",
    "    text = text.lower()\n",
    "    # 去除多余的空格\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "df['cleaned_review'] = df['review'].apply(clean_text)\n",
    "print(\"\\n文本清洗效果:\")\n",
    "print(df[['review', 'cleaned_review']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a876d5",
   "metadata": {},
   "source": [
    "## 3. 加载训练、验证数据\n",
    "先实例化一个分词器，分词器会先浏览所有规范化后的 review，统计每个词的出现频率，据此给词汇表中的每一个词分配一个序号表示这个词的重要程度（相当于创建了一个 dict），然后根据这个 dict 将每个 review 从词的序列映射到整数的序列。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b18eec9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T03:10:10.467459Z",
     "iopub.status.busy": "2025-06-27T03:10:10.467278Z",
     "iopub.status.idle": "2025-06-27T03:10:18.234924Z",
     "shell.execute_reply": "2025-06-27T03:10:18.234301Z",
     "shell.execute_reply.started": "2025-06-27T03:10:10.467442Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "填充后的训练数据形状: (35000, 200)\n",
      "填充后的测试数据形状: (15000, 200)\n"
     ]
    }
   ],
   "source": [
    "x = df['cleaned_review']\n",
    "y = df['sentiment']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=0, stratify=y)\n",
    "\n",
    "# 定义超参数\n",
    "vocab_size = 15000  # 词典中最大单词数\n",
    "max_len = 200       # 每条评论的最大长度\n",
    "embedding_dim = [16, 32, 64]  # 词向量维度\n",
    "\n",
    "# 创建一个分词器\n",
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token='<OOV>')\n",
    "\n",
    "# 使用分词器将 review（词的序列）转换为整数的序列便于处理\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "x_train_seq = tokenizer.texts_to_sequences(x_train)\n",
    "x_test_seq = tokenizer.texts_to_sequences(x_test)\n",
    "\n",
    "# 统一所有样本的序列长度为 max_len，若长度不足，填充 0；若长度超过，则截断\n",
    "x_train_pad = pad_sequences(x_train_seq, maxlen=max_len, padding='post', truncating='post')\n",
    "x_test_pad = pad_sequences(x_test_seq, maxlen=max_len, padding='post', truncating='post')\n",
    "print(f\"\\n填充后的训练数据形状: {x_train_pad.shape}\")\n",
    "print(f\"填充后的测试数据形状: {x_test_pad.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd260b5-0459-45f2-add8-59435f36f4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4. 尝试使用 SVM 进行预测\n",
    "一开始，我直接使用 `svm = SVC(kernel='linear', C=1.0) ` 来实例化模型并训练，但是速度非常慢，因为 SVM 的时间复杂度在 $O(n^2) \\sim O(n^3)$ 之间，在这里 n 大于 10000。所以改为使用 `svm = SGDClassifier(loss='hinge', max_iter=20, tol=1e-3)` 求得近似解。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ac0ff4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T03:48:51.055688Z",
     "iopub.status.busy": "2025-06-27T03:48:51.055388Z",
     "iopub.status.idle": "2025-06-27T03:48:56.708634Z",
     "shell.execute_reply": "2025-06-27T03:48:56.707676Z",
     "shell.execute_reply.started": "2025-06-27T03:48:51.055664Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8845333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=2000,\n",
    "    ngram_range=(1,1),\n",
    "    max_df=0.8,\n",
    "    min_df=10\n",
    ")\n",
    "t0 = time.time()\n",
    "X_tr = tfidf.fit_transform(x_train)\n",
    "X_te = tfidf.transform(x_test)\n",
    "t1 = time.time()\n",
    "\n",
    "svm = SGDClassifier(loss='hinge', max_iter=20, tol=1e-3)\n",
    "svm.fit(X_train_tfidf, y_train)\n",
    "\n",
    "y_pred = sgd_svm.predict(X_test_tfidf)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b83e53",
   "metadata": {},
   "source": [
    "## 4. 使用不同Embedding_dim参数实例化模型并训练，可视化训练过程\n",
    "这里构建了一个简单的 LSTM 网络，大致构造思路如下。在之前的步骤中，我将一个 review 字符串转化为了一个长度为200的词序号的序列（200， 0），如：`[5, 1, 7, 3, 6, ...]`。现在，我将这个序列作为模型的输入，希望输出一个值，表示文本情感的预测结果。\n",
    "\n",
    "然而，这种词序号的表示方式只能大致描述一下词的重要程度，但是对词意的把握并不精准，所以先添加一层 Embedding 层，将每一个词序号映射到一个 64 维的语义空间中，该层的输出为一个 (200, 64) 的矩阵，具体的映射函数由训练过程习得。\n",
    "\n",
    "有了上一层输出的矩阵，模型就能知道：输入字符串是由哪些词组成的；它们各自的含义是什么。但是，并不是很好的理解句子中的每一个词就能很好的理解句意的，理解句子需要联系上下文判断每个词的含义（如:\"虽然..., 但是...\"类型的句子），所以需要添加 LSTM 层。 这里添加了两层是因为感觉一层 LSTM 无法很好的捕捉所有的信息。\n",
    "\n",
    "之后再引入一层 Dropout 层是因为查阅资料时有提到过 LSTM 参数过多，可能会记住一些噪声，影响评估新样本时的性能，所以让网络随机忽略一半的单元，使得网络学习到的规律更具有普适性。\n",
    "\n",
    "最后，添加一个全连接层来把提炼出来的高层次特征进行组合（这里参数选择 32 个节点和 ReLU 激活函数），再把它送进只有一个神经元的输出层，使用 Sigmoid 激活函数，把结果压缩到 0～1 之间，作为最终的输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df82dc09",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-27T03:22:11.509141Z",
     "iopub.status.idle": "2025-06-27T03:22:11.509551Z",
     "shell.execute_reply": "2025-06-27T03:22:11.509448Z",
     "shell.execute_reply.started": "2025-06-27T03:22:11.509436Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.rcParams['font.sans-serif'] = ['Arial Unicode MS']\n",
    "matplotlib.rcParams['axes.unicode_minus'] = False\n",
    "accuracy = []\n",
    "plt.figure(figsize=(12, 4))\n",
    "for i in range(len(embedding_dim)):\n",
    "    dim = embedding_dim[i]\n",
    "    print(f\"\\n词向量维度: {dim}\")\n",
    "\n",
    "    model = Sequential([\n",
    "        # 嵌入层\n",
    "        Embedding(input_dim=vocab_size, output_dim=dim, input_length=max_len),\n",
    "        \n",
    "        # 双向LSTM (Bidirectional LSTM)层\n",
    "        Bidirectional(LSTM(units=32, return_sequences=True)),\n",
    "        \n",
    "        # 再添加一个LSTM层\n",
    "        Bidirectional(LSTM(units=24)),\n",
    "        \n",
    "        # 添加Dropout层防止过拟合\n",
    "        Dropout(0.5),\n",
    "        \n",
    "        # 全连接层\n",
    "        Dense(units=32, activation='relu'),\n",
    "        \n",
    "        # 输出层\n",
    "        Dense(units=1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    # 编译模型，使用adam作为优化器，二元交叉熵作为损失函数\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    # 定义超参数\n",
    "    epoch = 5\n",
    "    batch_size = 64  # 尝试不同的批次大小\n",
    "    # 训练模型\n",
    "    history = model.fit(\n",
    "        x_train_pad, y_train,\n",
    "        epochs=epoch,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(x_test_pad, y_test),\n",
    "        verbose=1\n",
    "    )\n",
    "    accuracy.append(history.history['val_accuracy'][-1])\n",
    "    plt.subplot(1, 3, i + 1)\n",
    "    plt.plot(history.history['val_accuracy'], label='Accuracy')\n",
    "    plt.title('Embedding_dim: {}'.format(dim))\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "        \n",
    "print(\"\\n模型训练完成!\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f7696d",
   "metadata": {},
   "source": [
    "## 5. 比较不同参数对模型预测准确性的影响\n",
    "下图展示的是对于不同 Embedding_dim(16, 32, 64) 的取值对模型准确度的影响。因为当前的二分类任务可能较简单，不对语义空间的维数有较高要求，所以在使用不同 Embedding_dim 时，模型准确度虽有差异但不明显。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c2490d-2394-4a40-9ad4-3075404c36a6",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-27T03:22:11.510140Z",
     "iopub.status.idle": "2025-06-27T03:22:11.510554Z",
     "shell.execute_reply": "2025-06-27T03:22:11.510454Z",
     "shell.execute_reply.started": "2025-06-27T03:22:11.510443Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "names = ['16', '32', '64']\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.bar(names, accuracy, color=['skyblue'])\n",
    "plt.xlabel('Embedding_dim')\n",
    "plt.title('Model Accuracy')\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "plt.xticks(np.arange(0, 3, 1))\n",
    "plt.ylim(0.84, 0.86)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
